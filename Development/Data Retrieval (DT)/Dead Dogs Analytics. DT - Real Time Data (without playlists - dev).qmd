---
title: "Dead Dogs Analytics. Data Retrieval - DEV"
subtitle: "Real Time Data (without playlists)"
author: "Alessandro Speranza"
date: "14/08/2022"
date-modified: "11/12/2022"
format: html
toc: true
editor: source
---

```{r}
#| include: false

knitr::opts_chunk$set(cash = TRUE,
                      cache.lazy = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      echo = TRUE,
                      dpi = 180,
                      fig.width = 8,
                      fig.height = 5)

library(tidyverse)
library(httr)
library(jsonlite)
```

## Get channel info using YouTube Data API - Real time Data

```{r}
channel_id <- "UC6CV_32l8omBfcliOOQnIew"

api_call_channel <- str_c("https://www.googleapis.com/youtube/v3/channels?key=AIzaSyCviXCt3rQPfDaNvuFIaWCE24gNx7q0Dfs&id=",channel_id,"&part=snippet,contentDetails,statistics&maxResults=15")

api_result_channel <- httr::GET(api_call_channel)

json_result_channel <- httr::content(api_result_channel, "text", encoding="UTF-8")

# Process the raw data into a data frame
json_channel <- jsonlite::fromJSON(json_result_channel, flatten = T)

channel_info <- as.data.frame(json_channel) %>% 
  janitor::clean_names()
```

## Get the complete list of channels videos (without playlist) using YouTube Data API - Real time Data

### Retrieve all the channel videos in the first page available

```{r}
# This method is used when a channels has published videos without a playlist

# Step 1: retrieve the nextPageToken from the first page 
uploads <- channel_info %>% 
  select(items_content_details_related_playlists_uploads) %>% 
  dplyr::pull()

# uploads key = "UU6CV_32l8omBfcliOOQnIew"

# Step 2: retrieve the uploads key from channel data frame
api_call_channel_videos_fp <- str_c("https://www.googleapis.com/youtube/v3/playlistItems?playlistId=", uploads, "&key=AIzaSyCviXCt3rQPfDaNvuFIaWCE24gNx7q0Dfs&part=snippet&maxResults=50")

api_result_channel_videos_fp <- httr::GET(api_call_channel_videos_fp)

json_result_channel_videos_fp <- httr::content(api_result_channel_videos_fp, "text", encoding="UTF-8")

# Process the raw data into a data frame
json_channel_videos_fp <- jsonlite::fromJSON(json_result_channel_videos_fp, flatten = T)

channel_videos <- as.data.frame(json_channel_videos_fp) %>% 
  janitor::clean_names() 

# Retrieve the first nextPageToken to pass to the function in order to retrieve all the other nextPageToken interactively
nextPageToken <- json_channel_videos_fp[["nextPageToken"]]
```

## Retrieve all the channel videos in the following pages available & create the final channel videos data frame

```{r}
# Function to retrieve all the nextPageToken available and create a dataframe with all the channel video details
get_all_nextPageTokens <- function (nextPageToken) {
  
  while (!is.null(nextPageToken)) {
    
    api_call_channel_videos_np <- str_c("https://www.googleapis.com/youtube/v3/playlistItems?playlistId=", uploads, "&pageToken=", nextPageToken, "&key=AIzaSyCviXCt3rQPfDaNvuFIaWCE24gNx7q0Dfs&part=snippet,status&maxResults=50")
    
    api_result_channel_videos_np <- httr::GET(api_call_channel_videos_np)
    
    json_result_channel_videos_np <- httr::content(api_result_channel_videos_np, "text", encoding="UTF-8")
    
    # Process the raw data into a data frame
    json_channel_videos_np <- jsonlite::fromJSON(json_result_channel_videos_np, flatten = T)
    
    channel_videos_np <- as.data.frame(json_channel_videos_np) %>% 
      janitor::clean_names()
    
    channel_videos <- dplyr::bind_rows(channel_videos, channel_videos_np) %>%
      janitor::clean_names() 
    
    nextPageToken <- json_channel_videos_np[["nextPageToken"]]
    
  }
  
    channel_videos
  
}

# Step 3: retrieve all the channel videos calling the function & rename the selected fields
channel_videos_info <- get_all_nextPageTokens (nextPageToken) %>%
  dplyr::rename(video_position = items_snippet_position,
                video_id = items_snippet_resource_id_video_id,
                video_title = items_snippet_title,
                video_description = items_snippet_description,
                video_published_date = items_snippet_published_at,
                video_status = items_status_privacy_status,
                playlist_id = items_snippet_playlist_id,
                channel_id = items_snippet_channel_id,
                channel_title = items_snippet_channel_title,
                total_videos = page_info_total_results,
                previous_page_token = prev_page_token) %>%
  dplyr::select(video_position,
                video_id,
                video_title,
                video_description,
                video_published_date,
                video_status,
                playlist_id,
                channel_id,
                channel_title,
                total_videos,
                next_page_token,
                previous_page_token)
```

## Get all the videos stats - Real time Data

```{r}
all_video_ids_vector <- channel_videos_info %>% 
  select(video_id) %>% 
  dplyr::pull()

get_all_videos_stats <- function(video_id) {
  
api_call_videos <- str_c("https://www.googleapis.com/youtube/v3/videos?key=AIzaSyCviXCt3rQPfDaNvuFIaWCE24gNx7q0Dfs&id=", video_id, "&part=contentDetails,recordingDetails,snippet,statistics,status,topicDetails&maxResults=50")  

api_result_videos <- httr::GET(api_call_videos)

json_result_videos <- httr::content(api_result_videos, "text", encoding="UTF-8")

# Process the raw data into a data frame
json_videos <- fromJSON(json_result_videos, flatten = T)

videos <- as.data.frame(json_videos) %>% 
   janitor::clean_names()  
  
}

video_stats <- map_df(all_video_ids_vector, get_all_videos_stats) %>% 
  mutate(items_statistics_view_count = as.integer(items_statistics_view_count),
         items_statistics_like_count = as.integer(items_statistics_like_count),
         items_statistics_favorite_count = as.integer(items_statistics_favorite_count),
         items_statistics_comment_count = as.integer(items_statistics_comment_count)) %>%
  rename(video_id = items_id,
         views = items_statistics_view_count,
         likes = items_statistics_like_count,
         favorites = items_statistics_favorite_count,
         comments = items_statistics_comment_count) %>% 
  select(video_id, 
         views, 
         likes,
         favorites,
         comments)
```

## Join playlist info & video stats - Real time Data

```{r}
final_video_stats <- channel_videos_info %>%
  inner_join(video_stats, by = "video_id")
```

## TO EVALUATE

# Get all the videos stats - Historical Data

```{r}
get_all_videos_hist_info <- function(video_id) {
  
request <- str_c("https://youtubeanalytics.googleapis.com/v2/reports?dimensions=day,video&metrics=views&filters=video==", video_id, "&sort=-day&startDate=2016-01-01&endDate=2099-12-31&ids=channel==MINE")

req_youtube <- GET(request, config(token = access_token))

youtube_text <- content(req_youtube, "text", encoding="UTF-8")

youtube_json <- fromJSON(youtube_text, flatten = TRUE)

videos_hist <- as.data.frame(youtube_json[["rows"]]) %>% 
  arrange(V1) %>%
  transmute(views_date = as.Date(V1),
            video_id = V2,
            video_daily_views = as.numeric(V3)) %>%
  complete(views_date = seq.Date(min(views_date), lubridate::today(), by = "day")) %>%
  fill(video_id) %>%
  mutate(video_daily_views = ifelse(is.na(video_daily_views), 0, video_daily_views))
  
}

all_videos_stats_hist <- map_df(all_video_ids_vector, get_all_videos_hist_info)
```

# Join playlist info & video hist stats - Historical Data

```{r}
playlists_videos_hist <- inner_join(all_videos_stats_hist, playlists_videos, by = "video_id")
```

# Adding cumulative views - Historical Data

```{r}
playlists_videos_hist_cum <- playlists_videos_hist %>%
  filter(video_id %in% c("YyS7cqFRUvI","29laglX3M1g")) %>%
  group_by(video_id) %>% 
  mutate(video_cum_views = cumsum(video_daily_views)) %>% 
  relocate(video_cum_views, .after = video_daily_views) %T>% # magrittr special pipe
  saveRDS(file = "data/playlists_videos_hist_cum.rds")
```
